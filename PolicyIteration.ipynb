{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1a0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyamaze import maze,COLOR,agent\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3af49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_value=20\n",
    "row_vaule=20\n",
    "test_maze=maze(rows=row_vaule,cols=col_value)\n",
    "test_maze.CreateMaze(loopPercent=10)\n",
    "# test_maze.CreateMaze(loadMaze='maze--mul_20_20.csv')\n",
    "test_maze_mapping=test_maze.maze_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32fd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retruns a 2d Array With 1 representing path and \n",
    "# Retruns a 2d Array With 1 representing path and \n",
    "def get_Matrix_mapping(test_maze, start_cell,goal_cell):\n",
    "    key_map=dict()\n",
    "    row=test_maze.rows\n",
    "    col=test_maze.cols\n",
    "    maze_mapping = test_maze.maze_map\n",
    "    maze_2d=np.full(((2*(row))-1,(2*(col))-1),-1)\n",
    "    maze_2d=np.pad(maze_2d, 1, mode='constant',constant_values= 1)\n",
    "    row_val_matrix=maze_2d.shape[0]\n",
    "    col_val_matrix=maze_2d.shape[1]\n",
    "    ## Filling Boarders with Walls \n",
    "    for r in range(row_val_matrix):\n",
    "        if(r % 2 !=0):\n",
    "            continue\n",
    "        for c in range(col_val_matrix):\n",
    "                maze_2d[r][c]=1\n",
    "    for c in range(col_val_matrix):\n",
    "        if(c % 2 !=0):\n",
    "            continue\n",
    "        for r in range(row_val_matrix):\n",
    "            maze_2d[r][c]=1\n",
    "    for row_map in range(row):\n",
    "        old_row=row_map+1\n",
    "        new_row=old_row+row_map\n",
    "        for col_map in range (col):\n",
    "            old_col=col_map+1\n",
    "            new_col=old_col+col_map\n",
    "            maze_2d[new_row][new_col]=0\n",
    "            new_points=(new_row,new_col)\n",
    "            old_points=(old_row,old_col)\n",
    "            key_map[new_points]=old_points\n",
    "            if(maze_mapping[(old_row,old_col)][\"W\"]==1):\n",
    "                maze_2d[new_row][(new_col-1)]=0\n",
    "            else:\n",
    "                maze_2d[new_row][(new_col-1)]=1 \n",
    "            if(maze_mapping[(old_row,old_col)][\"E\"]==1):\n",
    "                maze_2d[new_row][(new_col+1)]=0\n",
    "            else:\n",
    "                maze_2d[new_row][(new_col+1)]=1 \n",
    "            if(maze_mapping[(old_row,old_col)][\"N\"]==1):\n",
    "                maze_2d[(new_row-1)][(new_col)]=0\n",
    "            else:\n",
    "                maze_2d[(new_row-1)][(new_col)]=1 \n",
    "            if(maze_mapping[(old_row,old_col)][\"S\"]==1):\n",
    "                maze_2d[(new_row+1)][(new_col)]=0\n",
    "            else:\n",
    "                maze_2d[(new_row+1)][(new_col)]=1\n",
    "            maze_2d[goal_cell[0]][goal_cell[1]]=2\n",
    "    return maze_2d,key_map\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2769ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_optimal_path_maze(optimal_path,maze_matrix_key_mapping):\n",
    "    maze_path_val=list()\n",
    "    for ele in optimal_path:\n",
    "        if(ele in maze_matrix_key_mapping):\n",
    "            maze_path_val.append(k[ele])\n",
    "    final_path=dict()\n",
    "    for i in range(1,len(maze_path_val)):\n",
    "        final_path[maze_path_val[i]]=maze_path_val[i-1]\n",
    "    return final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b0e0513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_No_Iterations 956\n",
      "State 1608717\n",
      "--- Running Time : 12.677089929580688 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 18:51:04.617 python[3932:191016] IMKClient Stall detected, *please Report* your user scenario attaching a spindump (or sysdiagnose) that captures the problem - (imkxpc_bundleIdentifierWithReply:) block performed very slowly (12.79 secs).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "goal_cell=((2*(test_maze.rows))-1),((2*(test_maze.cols))-1)\n",
    "start_cell=(1,1)\n",
    "\n",
    "test_maze_2d, k=get_Matrix_mapping(test_maze,start_cell,goal_cell)\n",
    "end_reward = 100\n",
    "step_reward = -1\n",
    "discount_factor = 0.99\n",
    "max_iterations = 10000\n",
    "actions = {\n",
    "    \"UP\": (-1, 0),\n",
    "    \"DOWN\": (1, 0),\n",
    "    \"LEFT\": (0, -1),\n",
    "    \"RIGHT\": (0, 1)\n",
    "}\n",
    "\n",
    "# State Matrix is defined and initial state is assigned to 0\n",
    "states_matrix = [(r, c) for r in range(test_maze_2d.shape[0]) for c in range(test_maze_2d.shape[1])]\n",
    "state_value_function = {state: 0 for state in states_matrix}\n",
    "\n",
    "## Assign Policy and  Transition function\n",
    "\n",
    "policy_matrix = {state: np.random.choice(list(actions.keys())) for state in states_matrix}\n",
    "transition_function = {\n",
    "    state: {\n",
    "        action: {\n",
    "            next_state: 1 if test_maze_2d[next_state] != 1 else 0\n",
    "            for next_state in [tuple(np.array(state) + np.array(actions[action]))]\n",
    "            if (0 <= next_state[0] < test_maze_2d.shape[0]) and (0 <= next_state[1] < test_maze_2d.shape[1])\n",
    "        }\n",
    "        for action in actions.keys()\n",
    "    }\n",
    "    for state in states_matrix\n",
    "}\n",
    "start_time = time.time()\n",
    "## Performing Policy Iteration\n",
    "counter=0\n",
    "for i in range(max_iterations):\n",
    "    # evaluate the current policy\n",
    "    delta = 0\n",
    "    for state in states_matrix:\n",
    "        counter=counter+1\n",
    "        old_state_value = state_value_function[state]\n",
    "        action = policy_matrix[state]\n",
    "        state_value_function[state] = sum(\n",
    "            transition_function[state][action][next_state] * (\n",
    "                (end_reward if test_maze_2d[next_state] == 2 else 0) +\n",
    "                (step_reward if test_maze_2d[next_state] == 0 else 0) +\n",
    "                discount_factor * state_value_function[next_state]\n",
    "            )\n",
    "            for next_state in transition_function[state][action].keys()\n",
    "        )\n",
    "        delta = max(delta, abs(old_state_value - state_value_function[state]))\n",
    "\n",
    "    # check if the policy is optimal\n",
    "    if delta < 1e-6:\n",
    "        print(\"Total_No_Iterations\",i)\n",
    "        print(\"State\",counter)\n",
    "        break\n",
    "\n",
    "    # improve the policy\n",
    "    for state in states_matrix:\n",
    "        best_action = None\n",
    "        best_action_value = float(\"-inf\")\n",
    "        for action in actions.keys():\n",
    "            action_value = sum(\n",
    "                transition_function[state][action][next_state] * (\n",
    "                    (end_reward if test_maze_2d[next_state] == 2 else 0) +\n",
    "                    (step_reward if test_maze_2d[next_state] == 0 else 0) +\n",
    "                    discount_factor * state_value_function[next_state]\n",
    "                )\n",
    "                for next_state in transition_function[state][action].keys()\n",
    "            )\n",
    "            if action_value > best_action_value:\n",
    "                best_action = action\n",
    "                best_action_value = action_value\n",
    "        policy_matrix[state] = best_action\n",
    "\n",
    "# print(policy_matrix)\n",
    "# define the initial state and the list of actions\n",
    "current_state = (1, 1)\n",
    "actions_taken = []\n",
    "\n",
    "# follow the policy until the goal state is reached\n",
    "while test_maze_2d[current_state] != 2:\n",
    "    # add the current state to the list of actions\n",
    "    actions_taken.append(current_state)\n",
    "\n",
    "    # take the action prescribed by the policy\n",
    "    action = policy_matrix[current_state]\n",
    "    next_state = tuple(np.array(current_state) + np.array(actions[action]))\n",
    "    current_state = next_state\n",
    "\n",
    "# add the goal state to the list of actions\n",
    "actions_taken.append(current_state)\n",
    "\n",
    "# print the list of actions\n",
    "# print(\"Optimal path:\")\n",
    "# for state in actions_taken:\n",
    "#     print(state)\n",
    "exec_time = (time.time() - start_time)\n",
    "print(\"--- Running Time : %s seconds ---\" % exec_time)\n",
    "pt=map_optimal_path_maze(actions_taken,k)\n",
    "len(pt)\n",
    "a=agent(test_maze,footprints=True,color=COLOR.yellow,shape='arrow',filled=True)\n",
    "test_maze.tracePath({a:pt},delay=100)\n",
    "test_maze.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b11b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa401dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
